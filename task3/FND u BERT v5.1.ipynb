{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10531,
     "status": "ok",
     "timestamp": 1607362252934,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "dNwTQef3Zs_-",
    "outputId": "f6ae2c2f-3c86-4f6a-df6a-d86b466645eb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pytorch-transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytorch-transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytorch-transformers) (2.25.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytorch-transformers) (1.8.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytorch-transformers) (0.0.44)\n",
      "Requirement already satisfied: regex in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from pytorch-transformers) (2021.4.4)\n",
      "Requirement already satisfied: boto3 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytorch-transformers) (1.17.53)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytorch-transformers) (0.1.95)\n",
      "Requirement already satisfied: tqdm in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from pytorch-transformers) (4.60.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.53 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3->pytorch-transformers) (1.20.53)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3->pytorch-transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3->pytorch-transformers) (0.3.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from botocore<1.21.0,>=1.20.53->boto3->pytorch-transformers) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from botocore<1.21.0,>=1.20.53->boto3->pytorch-transformers) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.53->boto3->pytorch-transformers) (1.15.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->pytorch-transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->pytorch-transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->pytorch-transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->pytorch-transformers) (1.0.1)\n",
      "Installing collected packages: pytorch-transformers\n",
      "Successfully installed pytorch-transformers-1.2.0\n",
      "Requirement already satisfied: transformers in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: requests in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.0.44)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (3.6.1)\n",
      "Requirement already satisfied: regex in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\smsoh\\appdata\\roaming\\python\\python38\\site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\smsoh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    " #!pip install pytorch-transformers\n",
    " #!pip install transformers\n",
    " #!pip install nltk\n",
    " #!pip install preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11024,
     "status": "ok",
     "timestamp": 1607362253435,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "b4UVghcaWJ6Y",
    "outputId": "72aaf8ba-a883-4f8e-f2a0-63f6f10e772d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\smsoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\smsoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smsoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    " import nltk\n",
    " nltk.download('punkt')\n",
    " nltk.download('wordnet')\n",
    " nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 11947,
     "status": "ok",
     "timestamp": 1607362254364,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "uP3tG3qRZvja"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import preprocessor as p\n",
    "\n",
    "from transformers import XLMModel, BertTokenizer, BertForSequenceClassification, RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "from transformers import AdamW\n",
    "import nltk\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "# % matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11942,
     "status": "ok",
     "timestamp": 1607362254365,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "QYohf8eQZvmI",
    "outputId": "658553b7-3d5c-4782-e91e-e072bf682ab6"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-310c9020eba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \"\"\"\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \"\"\"\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# will define _get_device_properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  public_id                                              title  \\\n",
       "0  f2182a54  HUGE! Attorney Sidney Powell CONFIRMS Alleged ...   \n",
       "1  c5175d8d        Paul Ryan’s Worst Ally - The New York Times   \n",
       "2  213a870b  You Can Get Jail Time Or $3,000 Fine For Not W...   \n",
       "3  392886ea  Antifa gearing up for false flag violence disg...   \n",
       "4  bc6d5d55  Remarks by President Biden on the Administrati...   \n",
       "5  59960d0e                                   Infowars Article   \n",
       "6  b8437efb  BOMBSHELL: Covid-19 infection rate may be 440%...   \n",
       "7  faf024d6  Marine Corps. Rebukes Pelosi: “WE DON’T WORK F...   \n",
       "8  0f086930  You Can be Fined $2,500 And Banned From Drivin...   \n",
       "9  daafc154  Scott Walker still owes $1 million for preside...   \n",
       "\n",
       "                                                text       our rating  \n",
       "0  Last week Rep. Louie Gohmert told Chris Salced...            FALSE  \n",
       "1  WHATEVER drama plays out when Republicans meet...             TRUE  \n",
       "2  Source page URL  Title You Can Get Jail Time O...            FALSE  \n",
       "3  With merchants in Democrat-run cities boarding...            FALSE  \n",
       "4  State Dining Room  4:22 P.M. EST  THE PRESIDEN...  partially false  \n",
       "5  Keep up to date with our latest:  Have an impo...            FALSE  \n",
       "6  (Natural News) A 2012 study published in the j...            FALSE  \n",
       "7  Latest Breaking News: Martial Law Imminent  Ge...            FALSE  \n",
       "8  Smoking could be considered a distraction unde...            FALSE  \n",
       "9  Gov. Scott Walker said Friday his presidential...  partially false  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>public_id</th>\n      <th>title</th>\n      <th>text</th>\n      <th>our rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f2182a54</td>\n      <td>HUGE! Attorney Sidney Powell CONFIRMS Alleged ...</td>\n      <td>Last week Rep. Louie Gohmert told Chris Salced...</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c5175d8d</td>\n      <td>Paul Ryan’s Worst Ally - The New York Times</td>\n      <td>WHATEVER drama plays out when Republicans meet...</td>\n      <td>TRUE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>213a870b</td>\n      <td>You Can Get Jail Time Or $3,000 Fine For Not W...</td>\n      <td>Source page URL  Title You Can Get Jail Time O...</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>392886ea</td>\n      <td>Antifa gearing up for false flag violence disg...</td>\n      <td>With merchants in Democrat-run cities boarding...</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bc6d5d55</td>\n      <td>Remarks by President Biden on the Administrati...</td>\n      <td>State Dining Room  4:22 P.M. EST  THE PRESIDEN...</td>\n      <td>partially false</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>59960d0e</td>\n      <td>Infowars Article</td>\n      <td>Keep up to date with our latest:  Have an impo...</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b8437efb</td>\n      <td>BOMBSHELL: Covid-19 infection rate may be 440%...</td>\n      <td>(Natural News) A 2012 study published in the j...</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>faf024d6</td>\n      <td>Marine Corps. Rebukes Pelosi: “WE DON’T WORK F...</td>\n      <td>Latest Breaking News: Martial Law Imminent  Ge...</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0f086930</td>\n      <td>You Can be Fined $2,500 And Banned From Drivin...</td>\n      <td>Smoking could be considered a distraction unde...</td>\n      <td>FALSE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>daafc154</td>\n      <td>Scott Walker still owes $1 million for preside...</td>\n      <td>Gov. Scott Walker said Friday his presidential...</td>\n      <td>partially false</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/task_3a_sample_data.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.18, random_state=42)\n",
    "X_val, X_test = train_test_split(X_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 11936,
     "status": "ok",
     "timestamp": 1607362254365,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "H-9BIVc_aJb3"
   },
   "outputs": [],
   "source": [
    "df = X_train\n",
    "val_df = X_val\n",
    "test_df = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 11932,
     "status": "ok",
     "timestamp": 1607362254366,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "Gtf--uEfVE7C"
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer  = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) \n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 11929,
     "status": "ok",
     "timestamp": 1607362254366,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "EOO9UH0GvVSB"
   },
   "outputs": [],
   "source": [
    "#p.set_options(p.OPT.URL, p.OPT.EMOJI)\n",
    "\n",
    "def preprocess(row, lemmatizer, stemmer):\n",
    "    text = row['text']\n",
    "    # text = text.strip('\\xa0')\n",
    "    text = wordopt(text)\n",
    "    tokenization = nltk.word_tokenize(text)     \n",
    "    tokenization = [w for w in tokenization if not w in stop_words]\n",
    "    #   text = ' '.join([porter_stemmer.stem(w) for w in tokenization])\n",
    "    #   text = ' '.join([lemmatizer.lemmatize(w) for w in tokenization])\n",
    "    # text = re.sub(r'\\([0-9]+\\)', '', text).strip()    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 22070,
     "status": "ok",
     "timestamp": 1607362264511,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "SnpJ27eIvVU2"
   },
   "outputs": [],
   "source": [
    "df['text'] = df.apply(lambda x: preprocess(x, wordnet_lemmatizer, porter_stemmer), 1)\n",
    "val_df['text'] = val_df.apply(lambda x: preprocess(x, wordnet_lemmatizer, porter_stemmer), 1)\n",
    "test_df['text'] = test_df.apply(lambda x: preprocess(x, wordnet_lemmatizer, porter_stemmer), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 22056,
     "status": "ok",
     "timestamp": 1607362264522,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "_dHcpDJmbgaK"
   },
   "outputs": [],
   "source": [
    "df['our rating'] = df['our rating'].apply(lambda x: 1 if 'true' in x.lower() else ( 0 if 'partially false' in x.lower() else -1))\n",
    "val_df['our rating'] = val_df['our rating'].apply(lambda x: 1 if 'true' in x.lower() else ( 0 if 'partially false' in x.lower() else -1))\n",
    "# test_df['label_encoded'] = test_df.apply(lambda x: map_label(x), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   public_id                                              title  \\\n",
       "19  e2e93a55  Pro-Life Groups Upset UN Coronavirus Relief Fu...   \n",
       "12  c69de08e  Wisconsin Election Commission Directive Allows...   \n",
       "4   bc6d5d55  Remarks by President Biden on the Administrati...   \n",
       "37  aacdc4d3  Florida law house party underage drinking penalty   \n",
       "8   0f086930  You Can be Fined $2,500 And Banned From Drivin...   \n",
       "3   392886ea  Antifa gearing up for false flag violence disg...   \n",
       "6   b8437efb  BOMBSHELL: Covid-19 infection rate may be 440%...   \n",
       "41  30c605a1  CDC Exposed: Inflated Covid Deaths By 1600% Th...   \n",
       "46  d72c2323        BLM Has Rules for Whites Attending Protests   \n",
       "47  c03ed5db  Canadian Govt Publishes Bid Request For “Progr...   \n",
       "\n",
       "                                                 text  our rating  \n",
       "19  the united nations is using coronavirus aid to...          -1  \n",
       "12  this article has been updated to include more ...          -1  \n",
       "4   state dining room    p m  est  the president  ...           0  \n",
       "37  america s vote  will casey bishop make it into...           1  \n",
       "8   smoking could be considered a distraction unde...          -1  \n",
       "3   with merchants in democrat run cities boarding...          -1  \n",
       "6    natural news  a  study published in the journ...          -1  \n",
       "41  throughout the election  donald trump was batt...          -1  \n",
       "46   shares share tweet  blm pasted these  rules  ...          -1  \n",
       "47  is canada building covid death camps to  proce...          -1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>public_id</th>\n      <th>title</th>\n      <th>text</th>\n      <th>our rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19</th>\n      <td>e2e93a55</td>\n      <td>Pro-Life Groups Upset UN Coronavirus Relief Fu...</td>\n      <td>the united nations is using coronavirus aid to...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>c69de08e</td>\n      <td>Wisconsin Election Commission Directive Allows...</td>\n      <td>this article has been updated to include more ...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bc6d5d55</td>\n      <td>Remarks by President Biden on the Administrati...</td>\n      <td>state dining room    p m  est  the president  ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>aacdc4d3</td>\n      <td>Florida law house party underage drinking penalty</td>\n      <td>america s vote  will casey bishop make it into...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0f086930</td>\n      <td>You Can be Fined $2,500 And Banned From Drivin...</td>\n      <td>smoking could be considered a distraction unde...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>392886ea</td>\n      <td>Antifa gearing up for false flag violence disg...</td>\n      <td>with merchants in democrat run cities boarding...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b8437efb</td>\n      <td>BOMBSHELL: Covid-19 infection rate may be 440%...</td>\n      <td>natural news  a  study published in the journ...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>30c605a1</td>\n      <td>CDC Exposed: Inflated Covid Deaths By 1600% Th...</td>\n      <td>throughout the election  donald trump was batt...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>d72c2323</td>\n      <td>BLM Has Rules for Whites Attending Protests</td>\n      <td>shares share tweet  blm pasted these  rules  ...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>c03ed5db</td>\n      <td>Canadian Govt Publishes Bid Request For “Progr...</td>\n      <td>is canada building covid death camps to  proce...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 22046,
     "status": "ok",
     "timestamp": 1607362264522,
     "user": {
      "displayName": "ai projects",
      "photoUrl": "",
      "userId": "06097692587330186651"
     },
     "user_tz": -330
    },
    "id": "nkGKyR6ki-QQ"
   },
   "outputs": [],
   "source": [
    "train_sentences = df.text.values\n",
    "val_sentences = val_df.text.values\n",
    "test_sentences = test_df.text.values\n",
    "\n",
    "train_labels = df['our rating'].values\n",
    "val_labels = val_df['our rating'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encode_TextWithAttention(sentence,tokenizer,maxlen,padding_type='max_length',attention_mask_flag=True):\n",
    "    encoded_dict = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=maxlen, truncation=True, padding=padding_type, return_attention_mask=attention_mask_flag)\n",
    "    return encoded_dict['input_ids'],encoded_dict['attention_mask']\n",
    "\n",
    "def Encode_TextWithoutAttention(sentence,tokenizer,maxlen,padding_type='max_length',attention_mask_flag=False):\n",
    "    encoded_dict = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=maxlen, truncation=True, padding=padding_type, return_attention_mask=attention_mask_flag)\n",
    "    return encoded_dict['input_ids']\n",
    "\n",
    "def get_TokenizedTextWithAttentionMask(sentenceList, tokenizer):\n",
    "    token_ids_list,attention_mask_list = [],[]\n",
    "    for sentence in sentenceList:\n",
    "        token_ids,attention_mask = Encode_TextWithAttention(sentence,tokenizer,MAX_LEN)\n",
    "        token_ids_list.append(token_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "    return token_ids_list,attention_mask_list\n",
    "\n",
    "def get_TokenizedText(sentenceList, tokenizer):\n",
    "    token_ids_list = []\n",
    "    for sentence in sentenceList:\n",
    "        token_ids = Encode_TextWithoutAttention(sentence,tokenizer,MAX_LEN)\n",
    "        token_ids_list.append(token_ids)\n",
    "    return token_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token_ids,train_attention_masks = torch.tensor(get_TokenizedTextWithAttentionMask(train_sentences,tokenizer))\n",
    "val_token_ids,val_attention_masks = torch.tensor(get_TokenizedTextWithAttentionMask(val_sentences,tokenizer))\n",
    "test_token_ids,test_attention_masks = torch.tensor(get_TokenizedTextWithAttentionMask(test_sentences,tokenizer))\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_token_ids, train_attention_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(val_token_ids, val_attention_masks, val_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_token_ids, test_attention_masks)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 433/433 [00:00<00:00, 145kB/s]\n",
      "Downloading: 100%|██████████| 440M/440M [05:15<00:00, 1.39MB/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-97fbbaa634f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \"\"\"\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \"\"\"\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24280636718691284\n",
      "Validation Accuracy: 0.9510261194029851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:54<12:48, 54.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "Train loss: 0.08406997792682244\n",
      "Validation Accuracy: 0.9692164179104478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [01:54<12:11, 56.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "Train loss: 0.04595320224669294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [02:52<11:23, 56.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9678171641791045\n",
      "Train loss: 0.02257679407345826\n",
      "Validation Accuracy: 0.9720149253731343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [03:52<10:35, 57.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "Train loss: 0.009623487452184087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [04:51<09:40, 58.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9668843283582089\n",
      "Train loss: 0.018880103594294532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [05:49<08:44, 58.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9664179104477612\n",
      "Train loss: 0.006600219280278282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [06:48<07:46, 58.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9565565031982941\n",
      "Train loss: 0.003649169539329619\n",
      "Validation Accuracy: 0.9762126865671642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [07:48<06:50, 58.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "Train loss: 0.0025684113266173547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [08:46<05:52, 58.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9715485074626866\n",
      "Train loss: 0.004890563517845982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [09:45<04:53, 58.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9626865671641791\n",
      "Train loss: 0.006581660135954952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [10:44<03:54, 58.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9706156716417911\n",
      "Train loss: 0.013777846906887858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [11:42<02:55, 58.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9748134328358209\n",
      "Train loss: 0.0037284481454413587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [12:41<01:57, 58.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.972481343283582\n",
      "Train loss: 0.0007238056316226952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [13:39<00:58, 58.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9729477611940298\n",
      "Train loss: 0.005957126443243043\n",
      "Validation Accuracy: 0.9762126865671642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [14:39<00:00, 58.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_set = []\n",
    "best_val_accuracy = 0.90\n",
    "directory_path = ''\n",
    "epochs = 15\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        train_loss_set.append(loss.item())    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "          logits = output[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    Validation_Accuracy = (eval_accuracy/nb_eval_steps)\n",
    "    if(Validation_Accuracy >= best_val_accuracy):\n",
    "        torch.save(model.state_dict(), directory_path+'models/BERT_base_uncased_best_model.ckpt')\n",
    "        best_val_accuracy = Validation_Accuracy\n",
    "        print('Model Saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO5tT/jJ/rxZRPbOZbJ6Vwg",
   "collapsed_sections": [],
   "mount_file_id": "1-oltG18MOlxTpyiwd2iA5o2olMRc4f1u",
   "name": "ROBERTa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python388jvsc74a57bd0a8a565e09f07703efdc86ec03ccdbe7c8a022a338e4d0d45f87f70f34a61d8ea",
   "display_name": "Python 3.8.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "a8a565e09f07703efdc86ec03ccdbe7c8a022a338e4d0d45f87f70f34a61d8ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}